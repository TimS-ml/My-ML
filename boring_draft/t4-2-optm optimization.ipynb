{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "from boring_utils.utils import *\n",
    "\n",
    "%matplotlib inline \n",
    "init_graph()\n",
    "device = get_device()\n",
    "set_seed(42, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../data\"\n",
    "CHECKPOINT_PATH = \"../model/optm_func/\"\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html\n",
    "# transforms.Normalize(mean, std)\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_b = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = FashionMNIST(\n",
    "    root=DATASET_PATH, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_set = FashionMNIST(\n",
    "    root=DATASET_PATH, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=1024, shuffle=True, drop_last=False)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=1024, shuffle=True, drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=1024, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_no_trans = FashionMNIST(\n",
    "    root=DATASET_PATH, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform_b\n",
    ")\n",
    "\n",
    "test_loader_no_trans = DataLoader(\n",
    "    test_set_no_trans, batch_size=1024, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(dataset, data_loader):\n",
    "    # raw data, untransformed\n",
    "    cprint((dataset.data.float() / 255.0).mean().item())\n",
    "    cprint((dataset.data.float() / 255.0).std().item())\n",
    "\n",
    "    # transformed data\n",
    "    imgs, _ = next(iter(data_loader))\n",
    "    cprint(imgs.mean().item(), imgs.std().item())\n",
    "    cprint(imgs.max().item(), imgs.min().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mprint_data -> (dataset.data.float() / 255.0).mean().item():\u001b[0m\n",
      "0.2868492901325226\n",
      "\u001b[93mprint_data -> (dataset.data.float() / 255.0).std().item():\u001b[0m\n",
      "0.3524441719055176\n",
      "\u001b[93mprint_data -> imgs.mean().item():\u001b[0m\n",
      "-0.42312583327293396\n",
      "\u001b[93mprint_data -> imgs.std().item():\u001b[0m\n",
      "0.7069889307022095\n",
      "\u001b[93mprint_data -> imgs.max().item():\u001b[0m\n",
      "1.0\n",
      "\u001b[93mprint_data -> imgs.min().item():\u001b[0m\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "print_data(test_set, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mprint_data -> (dataset.data.float() / 255.0).mean().item():\u001b[0m\n",
      "0.2868492901325226\n",
      "\u001b[93mprint_data -> (dataset.data.float() / 255.0).std().item():\u001b[0m\n",
      "0.3524441719055176\n",
      "\u001b[93mprint_data -> imgs.mean().item():\u001b[0m\n",
      "0.2812195122241974\n",
      "\u001b[93mprint_data -> imgs.std().item():\u001b[0m\n",
      "0.34957683086395264\n",
      "\u001b[93mprint_data -> imgs.max().item():\u001b[0m\n",
      "1.0\n",
      "\u001b[93mprint_data -> imgs.min().item():\u001b[0m\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print_data(test_set_no_trans, test_loader_no_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_fn_by_name = {}\n",
    "\n",
    "class Tanh(nn.Module):\n",
    "    '''\n",
    "    https://pytorch.org/docs/master/generated/torch.nn.Tanh.html#torch.nn.Tanh\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
    "\n",
    "act_fn_by_name['tanh'] = Tanh\n",
    "\n",
    "\n",
    "class ReLU(nn.Module):\n",
    "    '''\n",
    "    https://pytorch.org/docs/master/generated/torch.nn.ReLU.html#torch.nn.ReLU\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        # return torch.max(0, x)\n",
    "        return x * (x > 0).float()\n",
    "\n",
    "act_fn_by_name['relu'] = ReLU\n",
    "\n",
    "\n",
    "class LeakyReLU(nn.Module):\n",
    "    '''\n",
    "    https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU\n",
    "    '''\n",
    "    def __init__(self, negative_slope=0.1):\n",
    "        super().__init__()\n",
    "        self.neg_slop = negative_slope\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.where(x > 0, x, self.neg_slop * x)\n",
    "\n",
    "act_fn_by_name['leakyrelu'] = LeakyReLU\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "act_fn_by_name['identity'] = Identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNN(nn.Module):\n",
    "    def __init__(self, act_fn, input_size=784, hidden_sizes=[512, 256, 256, 128], num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act_fn = act_fn\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Create the network based on the specified hidden sizes\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + hidden_sizes\n",
    "        for layer_index in range(1, len(layer_sizes)):\n",
    "            layers += [\n",
    "                nn.Linear(layer_sizes[layer_index-1], \n",
    "                          layer_sizes[layer_index]),\n",
    "                self.act_fn\n",
    "                ]\n",
    "        layers += [nn.Linear(layer_sizes[-1], num_classes)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # reshape img to flat tensor\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_file_name = lambda model_path, model_name, extension='.tar': os.path.join(model_path, model_name + extension)\n",
    "\n",
    "\n",
    "def load_model(model_path, model_name, act_fn, net=None, **kargs):\n",
    "    \"\"\"\n",
    "    Loads a saved model from disk.\n",
    "    \"\"\"\n",
    "    model_file = _get_file_name(model_path, model_name)\n",
    "    if net is None:\n",
    "        net = BaseNN(act_fn=act_fn, **kargs)\n",
    "    net.load_state_dict(torch.load(model_file, map_location=device))\n",
    "    return net\n",
    "\n",
    "\n",
    "def save_model(model, model_path, model_name):\n",
    "    \"\"\"\n",
    "    Given a model, we save the state_dict and hyperparameters.\n",
    "    \n",
    "    Inputs:\n",
    "        model - Network object to save parameters from\n",
    "        model_path - Path of the checkpoint directory\n",
    "        model_name - Name of the model (str)\n",
    "    \"\"\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_file = _get_file_name(model_path, model_name)\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "\n",
    "def test_model(net, data_loader):\n",
    "    \"\"\"\n",
    "    Test a model on a specified dataset.\n",
    "    \n",
    "    Inputs:\n",
    "        net - Trained model of type BaseNetwork\n",
    "        data_loader - DataLoader object of the dataset to test on (validation or test)\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    true_preds, count = 0., 0\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = net(imgs).argmax(dim=-1)\n",
    "            true_preds += (preds == labels).sum().item()\n",
    "            count += labels.shape[0]\n",
    "    test_acc = true_preds / count\n",
    "    return test_acc "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
