{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcecfacf-0f5c-4af9-a083-c40e140cefc4",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472f0d16-5dd9-4c9a-8d87-dddb60109a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9d4a668-5fa9-4e18-bcff-231eb3f6c386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f450c611e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d9f27-c528-4256-8c92-691d751c497d",
   "metadata": {},
   "source": [
    "## Basic RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803aad44-1b2f-4d3a-8069-2509cc3027c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca4501a-b3f6-46d8-893e-ff3a06ed4b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674af191-12db-4fdb-b9ec-62383b6933a1",
   "metadata": {},
   "source": [
    "### Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56314621-d0d1-4fdf-968c-99bad6906705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# (num_layers * num_directions, batch, hidden_size) \n",
    "# whether batch_first=True or False\n",
    "hidden = Variable(torch.randn(1, 1, 2))\n",
    "inputs = Variable(torch.Tensor([h, e, l, l, o]))\n",
    "\n",
    "for one in inputs:\n",
    "    one = one.view(1, 1, -1)\n",
    "    # Input: (batch, seq_len, input_size) when batch_first=True\n",
    "    out, hidden = cell(one, hidden)\n",
    "    print(\"one input size\", one.size(), \"out size\", out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44b1eb3-e647-4928-9132-73a2df37acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence input size torch.Size([1, 5, 4]) out size torch.Size([1, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# We can do the whole at once\n",
    "\n",
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "inputs = inputs.view(1, 5, -1)\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"sequence input size\", inputs.size(), \"out size\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e134013-297d-496f-b592-e8e13ec034c8",
   "metadata": {},
   "source": [
    "### Multiple batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64c17a1-e54d-42b1-a939-6753af2c1d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input size torch.Size([3, 5, 4]) out size torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "hidden = Variable(torch.randn(1, 3, 2))\n",
    "\n",
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "# 3 batches 'hello', 'eolll', 'lleel'\n",
    "# rank = (3, 5, 4)\n",
    "inputs = Variable(\n",
    "    torch.Tensor([[h, e, l, l, o], [e, o, l, l, l], [l, l, e, e, l]]))\n",
    "\n",
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "# B x S x I\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"batch input size\", inputs.size(), \"out size\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37b30f-e9b3-4f67-8cb5-f94023bb1341",
   "metadata": {},
   "source": [
    "### Remove batch first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cad2cc1-1556-4e09-b9a8-62fb0b5b5f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input size torch.Size([5, 3, 4]) out size torch.Size([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2)\n",
    "cell = nn.RNN(input_size=4, hidden_size=2)\n",
    "\n",
    "# The given dimensions dim0 and dim1 are [swapped].\n",
    "inputs = inputs.transpose(dim0=0, dim1=1)\n",
    "# Propagate input through RNN\n",
    "# Input: (seq_len, batch_size, input_size) when batch_first=False (default)\n",
    "# S x B x I\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"batch input size\", inputs.size(), \"out size\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65d76f-d54c-4f5e-ad7b-5711674ed8be",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "no dataloader yet...\n",
    "\n",
    "Teach hihell -> ihello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8602de4-f6b4-4f64-bf9e-ba891dea256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char: h; idx: 0; onehot: 1, 0, 0 ... 0\n",
    "#            0    1    2    3    4\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "\n",
    "# Teach hihell -> ihello\n",
    "x_data = [0, 1, 0, 2, 3, 3]  # hihell\n",
    "y_data = [1, 0, 2, 3, 3, 4]  # ihello\n",
    "\n",
    "one_hot_lookup = [\n",
    "    [1, 0, 0, 0, 0],  # 0\n",
    "    [0, 1, 0, 0, 0],  # 1\n",
    "    [0, 0, 1, 0, 0],  # 2\n",
    "    [0, 0, 0, 1, 0],  # 3\n",
    "    [0, 0, 0, 0, 1]   # 4\n",
    "]\n",
    "\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "# As we have one batch of samples, we will change them to variables only once\n",
    "inputs = Variable(torch.Tensor(x_one_hot))\n",
    "labels = Variable(torch.LongTensor(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4acfbb9-9f52-4b1b-96af-1d3a44088327",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_size = 5  # one-hot size\n",
    "hidden_size = 5  # output from the RNN. 5 to directly predict one-hot\n",
    "batch_size = 1  # one sentence\n",
    "sequence_length = 1  # One by one\n",
    "num_layers = 1  # one-layer rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303e29d-9505-4d94-95d0-e82bc4d00b7e",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1748a405-7dd0-423f-bb60-638ef952dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size,\n",
    "                          hidden_size=hidden_size,\n",
    "                          batch_first=True)\n",
    "\n",
    "    def forward(self, hidden, x):\n",
    "        # Reshape input (batch first)\n",
    "        # x: tensor([1., 0., 0., 0., 0.])\n",
    "        # it will add more dim to x\n",
    "        x = x.view(batch_size, sequence_length, input_size)\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        # Input: (batch, seq_len, input_size)\n",
    "        # hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        return hidden, out.view(-1, num_classes)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        return Variable(torch.zeros(num_layers, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8112b143-259b-4bde-88d5-37a093d3016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (rnn): RNN(5, 5, batch_first=True)\n",
      ")\n",
      "predicted string:  l\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 1, loss: 9.266\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 11, loss: 4.004\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 21, loss: 3.386\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 31, loss: 3.241\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 41, loss: 3.195\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 51, loss: 3.176\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 61, loss: 3.164\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 71, loss: 3.156\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "epoch: 81, loss: 3.148\n",
      "predicted string:  i\n",
      "predicted string:  h\n",
      "predicted string:  e\n",
      "predicted string:  l\n",
      "predicted string:  l\n",
      "predicted string:  o\n",
      "epoch: 91, loss: 3.139\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate RNN model\n",
    "model = Model()\n",
    "print(model)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    for data_in, label in zip(inputs, labels):\n",
    "        # print shape of inputs\n",
    "        # print(data_in, label)\n",
    "        # torch.Size([1, 1, 5]) torch.Size([1, 5])\n",
    "        hidden, output = model(hidden, data_in)\n",
    "\n",
    "        _, idx = output.max(1)\n",
    "        if epoch % 10 == 0:\n",
    "            print('predicted string: ', \n",
    "                  idx2char[idx.data[0]])  # visualize char in output\n",
    "            \n",
    "        # RuntimeError: dimension specified as 0 but tensor has no dimensions\n",
    "        # loss += criterion(output, label)\n",
    "        loss += criterion(output, torch.LongTensor([label]))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48b15f-f6ce-439a-93a2-acbcce33dabf",
   "metadata": {},
   "source": [
    "## RNN in Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1f2af0e-6a0c-4970-86da-77979dd9652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Variable(torch.Tensor([x_one_hot]))  # why?\n",
    "\n",
    "sequence_length = 6  # len(ihello) == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ceb198-73ec-4967-bffd-94f72ef3d824",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "232e4b43-0b08-45c5-b2c9-261ba69c5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.rnn = nn.RNN(input_size=self.input_size, \n",
    "                          hidden_size=self.hidden_size, \n",
    "                          batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
    "        h_0 = Variable(\n",
    "            torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        # Reshape input: batch size, seq len, input size\n",
    "        x.view(x.size(0), self.sequence_length, self.input_size)\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        # Input: (batch, seq_len, input_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x, h_0)\n",
    "        return out.view(-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00439456-c68f-4db1-8d7b-b87a3e0be9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(5, 5, batch_first=True)\n",
      ")\n",
      "epoch: 1, loss: 1.484\n",
      "Predicted string:  llllll\n",
      "epoch: 11, loss: 0.717\n",
      "Predicted string:  ihello\n",
      "epoch: 21, loss: 0.521\n",
      "Predicted string:  ihello\n",
      "epoch: 31, loss: 0.484\n",
      "Predicted string:  ihello\n",
      "epoch: 41, loss: 0.471\n",
      "Predicted string:  ihello\n",
      "epoch: 51, loss: 0.465\n",
      "Predicted string:  ihello\n",
      "epoch: 61, loss: 0.462\n",
      "Predicted string:  ihello\n",
      "epoch: 71, loss: 0.460\n",
      "Predicted string:  ihello\n",
      "epoch: 81, loss: 0.458\n",
      "Predicted string:  ihello\n",
      "epoch: 91, loss: 0.457\n",
      "Predicted string:  ihello\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate RNN model\n",
    "rnn = RNN(num_classes, input_size, hidden_size, num_layers)\n",
    "print(rnn)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    outputs = rnn(inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data))\n",
    "        print(\"Predicted string: \", ''.join(result_str))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f590e8-e734-40d2-8e49-0392a92dc870",
   "metadata": {},
   "source": [
    "## Use embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e687c9e-7d06-4174-96d9-9894f1b047ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[0, 1, 0, 2, 3, 3]]  # hihell\n",
    "\n",
    "inputs = Variable(torch.LongTensor(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f61c6d4a-1221-4d76-b2ce-a511d2d2117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 10  # embedding size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29bf84-9d5e-4d45-9d4c-7a722c501547",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35a4fd48-1072-4757-bd18-f3ac2676b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # this is new\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(input_size=embedding_size,\n",
    "                          hidden_size=5,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        h_0 = Variable(\n",
    "            torch.zeros(num_layers, x.size(0), hidden_size))\n",
    "\n",
    "        emb = self.embedding(x)\n",
    "        emb = emb.view(batch_size, sequence_length, -1)\n",
    "\n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "        out, _ = self.rnn(emb, h_0)\n",
    "        return self.fc(out.view(-1, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5bc797a-3793-4578-be13-8f836ee7e977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding): Embedding(5, 10)\n",
      "  (rnn): RNN(10, 5, batch_first=True)\n",
      "  (fc): Linear(in_features=5, out_features=5, bias=True)\n",
      ")\n",
      "epoch: 1, loss: 1.550\n",
      "Predicted string:  eoeiee\n",
      "epoch: 11, loss: 0.185\n",
      "Predicted string:  ihello\n",
      "epoch: 21, loss: 0.021\n",
      "Predicted string:  ihello\n",
      "epoch: 31, loss: 0.006\n",
      "Predicted string:  ihello\n",
      "epoch: 41, loss: 0.004\n",
      "Predicted string:  ihello\n",
      "epoch: 51, loss: 0.003\n",
      "Predicted string:  ihello\n",
      "epoch: 61, loss: 0.002\n",
      "Predicted string:  ihello\n",
      "epoch: 71, loss: 0.002\n",
      "Predicted string:  ihello\n",
      "epoch: 81, loss: 0.002\n",
      "Predicted string:  ihello\n",
      "epoch: 91, loss: 0.001\n",
      "Predicted string:  ihello\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate RNN model\n",
    "model = Model()\n",
    "print(model)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    outputs = model(inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data))\n",
    "        print(\"Predicted string: \", ''.join(result_str))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
