{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- [ ] More Tensor Ops from d2l and my note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15334/2001084439.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf')  # For export\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_rgba\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline \n",
    "set_matplotlib_formats('svg', 'pdf')  # For export\n",
    "\n",
    "import torch\n",
    "from boring_utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign Values to Tensor\n",
    "\n",
    "To directly assign values to the tensor during initialization, there are many alternatives including:\n",
    "\n",
    "* `torch.zeros`: Creates a tensor filled with zeros\n",
    "* `torch.ones`: Creates a tensor filled with ones\n",
    "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
    "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide\n",
    "* `torch.from_numpy`: Converts a numpy array into a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x:\u001b[0m\n",
      "tensor([[[ 1.4013e-45,  0.0000e+00,  1.4013e-45,  0.0000e+00],\n",
      "         [ 1.2728e-05,  4.0604e-41,  1.4013e-45,  7.1435e+31],\n",
      "         [ 1.3205e-05,  4.0604e-41,  1.3206e-05,  4.0604e-41]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  7.0625e-43,  0.0000e+00],\n",
      "         [ 2.8026e-45,  0.0000e+00,  1.3206e-05,  4.0604e-41],\n",
      "         [-2.2104e-22,  3.0712e-41,  4.2039e-45,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2, 3, 4)\n",
    "cprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x:\u001b[0m\n",
      "tensor([[[-2.0993e+00,  2.2594e+00, -8.8424e-01,  7.5328e-01],\n",
      "         [-7.3936e-01,  1.4778e+00,  9.5404e-01,  3.7945e-01],\n",
      "         [ 8.3714e-01,  1.0330e+00,  3.3841e-01,  2.4910e+00]],\n",
      "\n",
      "        [[-1.6248e+00, -4.9452e-01, -1.6559e+00, -1.3338e+00],\n",
      "         [-9.0200e-04, -2.0273e-01, -2.6124e-02, -2.3574e+00],\n",
      "         [ 2.5105e+00, -9.1110e-01, -4.6658e-01,  8.9686e-02]]])\n",
      "\u001b[93m<module> -> x.shape:\u001b[0m\n",
      "torch.Size([2, 3, 4])\n",
      "\u001b[93m<module> -> x.size():\u001b[0m\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.tensor([[1, 2], [3, 4]])\n",
    "x = torch.randn([2, 3, 4])\n",
    "cprint(x, x.shape, x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `x1 + x2` creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor. We therefore change the values of `x2` without the chance to re-accessing the values of `x2` before the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4396, 1.6564, 1.4042],\n",
       "        [1.4909, 0.9187, 1.3233]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "\n",
    "y = x1 + x2\n",
    "x2.add_(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> id(y):\u001b[0m\n",
      "124451900923776\n",
      "\u001b[93m<module> -> id(x1):\u001b[0m\n",
      "124451900932016\n",
      "\u001b[93m<module> -> id(x2):\u001b[0m\n",
      "124451900918656\n",
      "\u001b[93m<module> -> y == x2:\u001b[0m\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# address of y:\n",
    "cprint(id(y), id(x1), id(x2))\n",
    "# cprint(y, x1, x2)\n",
    "cprint(y == x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x.shape:\u001b[0m\n",
      "torch.Size([6])\n",
      "\u001b[93m<module> -> x.shape:\u001b[0m\n",
      "torch.Size([2, 3])\n",
      "\u001b[93m<module> -> x.shape:\u001b[0m\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# original shape\n",
    "x = torch.arange(0, 6)\n",
    "cprint(x.shape)\n",
    "\n",
    "x = x.view(2, 3)\n",
    "cprint(x.shape)\n",
    "\n",
    "# swap dim 0 and 1\n",
    "x = x.permute(1, 0)\n",
    "cprint(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplications\n",
    "Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$. There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n",
    "\n",
    "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Can also be written as `a @ b`, similar to numpy. \n",
    "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
    "* `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
    "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1.\n",
    "\n",
    "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> h.shape:\u001b[0m\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "\n",
    "W = torch.arange(12).view(3, 4)\n",
    "\n",
    "h = x @ W\n",
    "cprint(h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x:\u001b[0m\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "cprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x[:, 1]:\u001b[0m\n",
      "tensor([1, 5, 9])\n",
      "\u001b[93m<module> -> x[0]:\u001b[0m\n",
      "tensor([0, 1, 2, 3])\n",
      "\u001b[93m<module> -> x[:2, -1]:\u001b[0m\n",
      "tensor([3, 7])\n",
      "\u001b[93m<module> -> x[len(x[0])//2:, :]:\u001b[0m\n",
      "tensor([[ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 2nd col\n",
    "cprint(x[:, 1])\n",
    "\n",
    "# 1st row\n",
    "cprint(x[0])\n",
    "\n",
    "# elements of the tensor x that are both in first two rows and the last column \n",
    "cprint(x[:2, -1])\n",
    "\n",
    "# 2nd half of the tensor x \n",
    "cprint(x[len(x[0])//2:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x:\u001b[0m\n",
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((3,))\n",
    "cprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x.requires_grad:\u001b[0m\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "cprint(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
    "\n",
    "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
    "\n",
    "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x:\u001b[0m\n",
      "tensor([0., 1., 2.], requires_grad=True)\n",
      "\u001b[93m<module> -> y:\u001b[0m\n",
      "tensor(12.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: only float tensors can require gradients!!!\n",
    "x = torch.arange(3, dtype=torch.float32, requires_grad=True)\n",
    "cprint(x)\n",
    "\n",
    "# Ops: (add -> a, square -> b, add -> c, mean -> y)\n",
    "a = x + 2\n",
    "b = a ** 2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "\n",
    "cprint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x.grad:\u001b[0m\n",
      "None\n",
      "\u001b[93m<module> -> x.grad:\u001b[0m\n",
      "tensor([1.3333, 2.0000, 2.6667])\n"
     ]
    }
   ],
   "source": [
    "cprint(x.grad)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "cprint(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> torch.cuda.is_available():\u001b[0m\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cprint(torch.cuda.is_available())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m<module> -> x:\u001b[0m\n",
      "tensor([0., 1., 2.], device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = x.to(device)\n",
    "cprint(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
