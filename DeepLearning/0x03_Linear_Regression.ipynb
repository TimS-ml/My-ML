{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A--sgCKzn9oD"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFBDBTV_n9oE"
   },
   "source": [
    "## Simple input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5Gd8ez6n9oF"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "giA9i3Unn9oM"
   },
   "outputs": [],
   "source": [
    "# Training data and ground truth\n",
    "x_data = tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = tensor([[2.0], [4.0], [6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEytgyTRn9oS"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)  # One in and one out\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWMZ2Zl-n9oW",
    "outputId": "3e22e72b-4a95-465b-e87d-48410d2cdbba",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6 \nEpoch: 7 | Loss: 0.4778628349304199 \nEpoch: 8 | Loss: 0.4561198353767395 \nEpoch: 9 | Loss: 0.4429425001144409 \nEpoch: 10 | Loss: 0.43362879753112793 \nEpoch: 11 | Loss: 0.4260846674442291 \nEpoch: 12 | Loss: 0.4193767011165619 \nEpoch: 13 | Loss: 0.4130893051624298 \nEpoch: 14 | Loss: 0.4070369005203247 \nEpoch: 15 | Loss: 0.4011355936527252 \nEpoch: 16 | Loss: 0.3953476548194885 \nEpoch: 17 | Loss: 0.38965579867362976 \nEpoch: 18 | Loss: 0.38405102491378784 \nEpoch: 19 | Loss: 0.37852954864501953 \nEpoch: 20 | Loss: 0.3730887770652771 \nEpoch: 21 | Loss: 0.36772680282592773 \nEpoch: 22 | Loss: 0.3624417185783386 \nEpoch: 23 | Loss: 0.3572330176830292 \nEpoch: 24 | Loss: 0.3520984351634979 \nEpoch: 25 | Loss: 0.3470384478569031 \nEpoch: 26 | Loss: 0.3420508801937103 \nEpoch: 27 | Loss: 0.3371349573135376 \nEpoch: 28 | Loss: 0.33229005336761475 \nEpoch: 29 | Loss: 0.3275144696235657 \nEpoch: 30 | Loss: 0.3228074312210083 \nEpoch: 31 | Loss: 0.3181682229042053 \nEpoch: 32 | Loss: 0.31359580159187317 \nEpoch: 33 | Loss: 0.3090890049934387 \nEpoch: 34 | Loss: 0.30464687943458557 \nEpoch: 35 | Loss: 0.3002682328224182 \nEpoch: 36 | Loss: 0.29595285654067993 \nEpoch: 37 | Loss: 0.29169976711273193 \nEpoch: 38 | Loss: 0.2875078618526459 \nEpoch: 39 | Loss: 0.28337568044662476 \nEpoch: 40 | Loss: 0.2793031632900238 \nEpoch: 41 | Loss: 0.27528905868530273 \nEpoch: 42 | Loss: 0.27133283019065857 \nEpoch: 43 | Loss: 0.267433226108551 \nEpoch: 44 | Loss: 0.2635899782180786 \nEpoch: 45 | Loss: 0.2598016858100891 \nEpoch: 46 | Loss: 0.2560679018497467 \nEpoch: 47 | Loss: 0.2523878812789917 \nEpoch: 48 | Loss: 0.24876070022583008 \nEpoch: 49 | Loss: 0.24518556892871857 \nEpoch: 50 | Loss: 0.24166196584701538 \nEpoch: 51 | Loss: 0.23818860948085785 \nEpoch: 52 | Loss: 0.23476573824882507 \nEpoch: 53 | Loss: 0.23139160871505737 \nEpoch: 54 | Loss: 0.22806601226329803 \nEpoch: 55 | Loss: 0.22478839755058289 \nEpoch: 56 | Loss: 0.22155779600143433 \nEpoch: 57 | Loss: 0.21837373077869415 \nEpoch: 58 | Loss: 0.21523530781269073 \nEpoch: 59 | Loss: 0.21214213967323303 \nEpoch: 60 | Loss: 0.20909328758716583 \nEpoch: 61 | Loss: 0.20608839392662048 \nEpoch: 62 | Loss: 0.20312657952308655 \nEpoch: 63 | Loss: 0.2002071589231491 \nEpoch: 64 | Loss: 0.19732996821403503 \nEpoch: 65 | Loss: 0.1944940686225891 \nEpoch: 66 | Loss: 0.1916988492012024 \nEpoch: 67 | Loss: 0.1889437437057495 \nEpoch: 68 | Loss: 0.186228409409523 \nEpoch: 69 | Loss: 0.1835518777370453 \nEpoch: 70 | Loss: 0.18091420829296112 \nEpoch: 71 | Loss: 0.17831432819366455 \nEpoch: 72 | Loss: 0.17575138807296753 \nEpoch: 73 | Loss: 0.17322571575641632 \nEpoch: 74 | Loss: 0.1707361936569214 \nEpoch: 75 | Loss: 0.16828221082687378 \nEpoch: 76 | Loss: 0.16586384177207947 \nEpoch: 77 | Loss: 0.1634802371263504 \nEpoch: 78 | Loss: 0.1611306220293045 \nEpoch: 79 | Loss: 0.15881498157978058 \nEpoch: 80 | Loss: 0.15653255581855774 \nEpoch: 81 | Loss: 0.1542830765247345 \nEpoch: 82 | Loss: 0.15206575393676758 \nEpoch: 83 | Loss: 0.14988036453723907 \nEpoch: 84 | Loss: 0.14772626757621765 \nEpoch: 85 | Loss: 0.14560319483280182 \nEpoch: 86 | Loss: 0.1435106098651886 \nEpoch: 87 | Loss: 0.1414482742547989 \nEpoch: 88 | Loss: 0.13941536843776703 \nEpoch: 89 | Loss: 0.13741177320480347 \nEpoch: 90 | Loss: 0.13543686270713806 \nEpoch: 91 | Loss: 0.13349035382270813 \nEpoch: 92 | Loss: 0.131571963429451 \nEpoch: 93 | Loss: 0.1296810805797577 \nEpoch: 94 | Loss: 0.12781746685504913 \nEpoch: 95 | Loss: 0.12598034739494324 \nEpoch: 96 | Loss: 0.12416988611221313 \nEpoch: 97 | Loss: 0.12238547205924988 \nEpoch: 98 | Loss: 0.12062644213438034 \nEpoch: 99 | Loss: 0.11889292299747467 \nEpoch: 100 | Loss: 0.11718425899744034 \nEpoch: 101 | Loss: 0.11550013720989227 \nEpoch: 102 | Loss: 0.11384030431509018 \nEpoch: 103 | Loss: 0.11220400035381317 \nEpoch: 104 | Loss: 0.11059156805276871 \nEpoch: 105 | Loss: 0.10900222510099411 \nEpoch: 106 | Loss: 0.10743551701307297 \nEpoch: 107 | Loss: 0.10589176416397095 \nEpoch: 108 | Loss: 0.1043698713183403 \nEpoch: 109 | Loss: 0.10286983847618103 \nEpoch: 110 | Loss: 0.10139142721891403 \nEpoch: 111 | Loss: 0.09993414580821991 \nEpoch: 112 | Loss: 0.09849793463945389 \nEpoch: 113 | Loss: 0.09708242118358612 \nEpoch: 114 | Loss: 0.09568724036216736 \nEpoch: 115 | Loss: 0.09431199729442596 \nEpoch: 116 | Loss: 0.09295668452978134 \nEpoch: 117 | Loss: 0.09162075817584991 \nEpoch: 118 | Loss: 0.09030386805534363 \nEpoch: 119 | Loss: 0.08900617063045502 \nEpoch: 120 | Loss: 0.08772709965705872 \nEpoch: 121 | Loss: 0.08646633476018906 \nEpoch: 122 | Loss: 0.08522358536720276 \nEpoch: 123 | Loss: 0.08399876952171326 \nEpoch: 124 | Loss: 0.08279159665107727 \nEpoch: 125 | Loss: 0.08160185068845749 \nEpoch: 126 | Loss: 0.0804290696978569 \nEpoch: 127 | Loss: 0.07927308976650238 \nEpoch: 128 | Loss: 0.07813374698162079 \nEpoch: 129 | Loss: 0.07701083272695541 \nEpoch: 130 | Loss: 0.0759042501449585 \nEpoch: 131 | Loss: 0.07481332123279572 \nEpoch: 132 | Loss: 0.07373811304569244 \nEpoch: 133 | Loss: 0.07267843931913376 \nEpoch: 134 | Loss: 0.0716339722275734 \nEpoch: 135 | Loss: 0.07060430943965912 \nEpoch: 136 | Loss: 0.06958970427513123 \nEpoch: 137 | Loss: 0.06858959794044495 \nEpoch: 138 | Loss: 0.06760384142398834 \nEpoch: 139 | Loss: 0.06663215160369873 \nEpoch: 140 | Loss: 0.0656745508313179 \nEpoch: 141 | Loss: 0.06473072618246078 \nEpoch: 142 | Loss: 0.06380042433738708 \nEpoch: 143 | Loss: 0.06288348883390427 \nEpoch: 144 | Loss: 0.06197984516620636 \nEpoch: 145 | Loss: 0.061089128255844116 \nEpoch: 146 | Loss: 0.060211122035980225 \nEpoch: 147 | Loss: 0.059345752000808716 \nEpoch: 148 | Loss: 0.058492954820394516 \nEpoch: 149 | Loss: 0.05765227600932121 \nEpoch: 150 | Loss: 0.05682387948036194 \nEpoch: 151 | Loss: 0.05600704997777939 \nEpoch: 152 | Loss: 0.05520214885473251 \nEpoch: 153 | Loss: 0.054408859461545944 \nEpoch: 154 | Loss: 0.05362694337964058 \nEpoch: 155 | Loss: 0.052856165915727615 \nEpoch: 156 | Loss: 0.0520966500043869 \nEpoch: 157 | Loss: 0.05134793370962143 \nEpoch: 158 | Loss: 0.050609905272722244 \nEpoch: 159 | Loss: 0.04988256096839905 \nEpoch: 160 | Loss: 0.049165692180395126 \nEpoch: 161 | Loss: 0.048459041863679886 \nEpoch: 162 | Loss: 0.0477626696228981 \nEpoch: 163 | Loss: 0.047076255083084106 \nEpoch: 164 | Loss: 0.04639975726604462 \nEpoch: 165 | Loss: 0.04573287442326546 \nEpoch: 166 | Loss: 0.045075610280036926 \nEpoch: 167 | Loss: 0.04442780464887619 \nEpoch: 168 | Loss: 0.04378927871584892 \nEpoch: 169 | Loss: 0.04315994679927826 \nEpoch: 170 | Loss: 0.042539697140455246 \nEpoch: 171 | Loss: 0.04192829877138138 \nEpoch: 172 | Loss: 0.041325852274894714 \nEpoch: 173 | Loss: 0.04073178768157959 \nEpoch: 174 | Loss: 0.040146395564079285 \nEpoch: 175 | Loss: 0.03956951946020126 \nEpoch: 176 | Loss: 0.03900088369846344 \nEpoch: 177 | Loss: 0.0384402833878994 \nEpoch: 178 | Loss: 0.037887852638959885 \nEpoch: 179 | Loss: 0.03734331578016281 \nEpoch: 180 | Loss: 0.0368066132068634 \nEpoch: 181 | Loss: 0.03627771884202957 \nEpoch: 182 | Loss: 0.035756323486566544 \nEpoch: 183 | Loss: 0.0352424681186676 \nEpoch: 184 | Loss: 0.034735970199108124 \nEpoch: 185 | Loss: 0.03423676639795303 \nEpoch: 186 | Loss: 0.03374465927481651 \nEpoch: 187 | Loss: 0.033259693533182144 \nEpoch: 188 | Loss: 0.032781802117824554 \nEpoch: 189 | Loss: 0.032310616225004196 \nEpoch: 190 | Loss: 0.031846266239881516 \nEpoch: 191 | Loss: 0.031388573348522186 \nEpoch: 192 | Loss: 0.03093741275370121 \nEpoch: 193 | Loss: 0.03049287013709545 \nEpoch: 194 | Loss: 0.030054621398448944 \nEpoch: 195 | Loss: 0.02962266281247139 \nEpoch: 196 | Loss: 0.029196925461292267 \nEpoch: 197 | Loss: 0.02877740189433098 \nEpoch: 198 | Loss: 0.028363777324557304 \nEpoch: 199 | Loss: 0.02795610949397087 \nEpoch: 200 | Loss: 0.027554377913475037 \nEpoch: 201 | Loss: 0.027158405631780624 \nEpoch: 202 | Loss: 0.02676806040108204 \nEpoch: 203 | Loss: 0.02638331614434719 \nEpoch: 204 | Loss: 0.02600415050983429 \nEpoch: 205 | Loss: 0.02563050575554371 \nEpoch: 206 | Loss: 0.025262102484703064 \nEpoch: 207 | Loss: 0.02489900216460228 \nEpoch: 208 | Loss: 0.024541253224015236 \nEpoch: 209 | Loss: 0.024188516661524773 \nEpoch: 210 | Loss: 0.023840945214033127 \nEpoch: 211 | Loss: 0.023498287424445152 \nEpoch: 212 | Loss: 0.023160550743341446 \nEpoch: 213 | Loss: 0.02282768487930298 \nEpoch: 214 | Loss: 0.022499671205878258 \nEpoch: 215 | Loss: 0.022176265716552734 \nEpoch: 216 | Loss: 0.02185750938951969 \nEpoch: 217 | Loss: 0.021543428301811218 \nEpoch: 218 | Loss: 0.02123377099633217 \nEpoch: 219 | Loss: 0.02092868648469448 \nEpoch: 220 | Loss: 0.020627887919545174 \nEpoch: 221 | Loss: 0.020331479609012604 \nEpoch: 222 | Loss: 0.02003924362361431 \nEpoch: 223 | Loss: 0.01975127123296261 \nEpoch: 224 | Loss: 0.019467417150735855 \nEpoch: 225 | Loss: 0.019187577068805695 \nEpoch: 226 | Loss: 0.018911898136138916 \nEpoch: 227 | Loss: 0.018640054389834404 \nEpoch: 228 | Loss: 0.01837216503918171 \nEpoch: 229 | Loss: 0.018108170479536057 \nEpoch: 230 | Loss: 0.017847927287220955 \nEpoch: 231 | Loss: 0.017591357231140137 \nEpoch: 232 | Loss: 0.0173385888338089 \nEpoch: 233 | Loss: 0.01708940789103508 \nEpoch: 234 | Loss: 0.016843784600496292 \nEpoch: 235 | Loss: 0.016601689159870148 \nEpoch: 236 | Loss: 0.01636316627264023 \nEpoch: 237 | Loss: 0.01612795703113079 \nEpoch: 238 | Loss: 0.015896158292889595 \nEpoch: 239 | Loss: 0.015667732805013657 \nEpoch: 240 | Loss: 0.015442508272826672 \nEpoch: 241 | Loss: 0.015220599249005318 \nEpoch: 242 | Loss: 0.015001876279711723 \nEpoch: 243 | Loss: 0.014786222018301487 \nEpoch: 244 | Loss: 0.014573737047612667 \nEpoch: 245 | Loss: 0.01436432171612978 \nEpoch: 246 | Loss: 0.014157848432660103 \nEpoch: 247 | Loss: 0.01395438052713871 \nEpoch: 248 | Loss: 0.013753843493759632 \nEpoch: 249 | Loss: 0.013556153513491154 \nEpoch: 250 | Loss: 0.013361378572881222 \nEpoch: 251 | Loss: 0.013169296085834503 \nEpoch: 252 | Loss: 0.012980060651898384 \nEpoch: 253 | Loss: 0.012793529778718948 \nEpoch: 254 | Loss: 0.012609641999006271 \nEpoch: 255 | Loss: 0.012428458780050278 \nEpoch: 256 | Loss: 0.012249830178916454 \nEpoch: 257 | Loss: 0.012073732912540436 \nEpoch: 258 | Loss: 0.011900248937308788 \nEpoch: 259 | Loss: 0.011729242280125618 \nEpoch: 260 | Loss: 0.011560623534023762 \nEpoch: 261 | Loss: 0.011394554749131203 \nEpoch: 262 | Loss: 0.011230770498514175 \nEpoch: 263 | Loss: 0.011069359257817268 \nEpoch: 264 | Loss: 0.010910294950008392 \nEpoch: 265 | Loss: 0.01075347326695919 \nEpoch: 266 | Loss: 0.010598905384540558 \nEpoch: 267 | Loss: 0.01044661458581686 \nEpoch: 268 | Loss: 0.010296465829014778 \nEpoch: 269 | Loss: 0.010148515924811363 \nEpoch: 270 | Loss: 0.010002671740949154 \nEpoch: 271 | Loss: 0.00985892303287983 \nEpoch: 272 | Loss: 0.009717240929603577 \nEpoch: 273 | Loss: 0.009577516466379166 \nEpoch: 274 | Loss: 0.00943993404507637 \nEpoch: 275 | Loss: 0.009304238483309746 \nEpoch: 276 | Loss: 0.009170528501272202 \nEpoch: 277 | Loss: 0.00903873611241579 \nEpoch: 278 | Loss: 0.008908831514418125 \nEpoch: 279 | Loss: 0.008780759759247303 \nEpoch: 280 | Loss: 0.008654605597257614 \nEpoch: 281 | Loss: 0.008530228398740292 \nEpoch: 282 | Loss: 0.008407631888985634 \nEpoch: 283 | Loss: 0.008286795578897 \nEpoch: 284 | Loss: 0.008167700842022896 \nEpoch: 285 | Loss: 0.008050356060266495 \nEpoch: 286 | Loss: 0.007934645749628544 \nEpoch: 287 | Loss: 0.007820612750947475 \nEpoch: 288 | Loss: 0.007708206307142973 \nEpoch: 289 | Loss: 0.007597408723086119 \nEpoch: 290 | Loss: 0.007488193456083536 \nEpoch: 291 | Loss: 0.007380598224699497 \nEpoch: 292 | Loss: 0.00727452477440238 \nEpoch: 293 | Loss: 0.007169992662966251 \nEpoch: 294 | Loss: 0.007066940423101187 \nEpoch: 295 | Loss: 0.006965361535549164 \nEpoch: 296 | Loss: 0.006865279749035835 \nEpoch: 297 | Loss: 0.006766629870980978 \nEpoch: 298 | Loss: 0.006669335067272186 \nEpoch: 299 | Loss: 0.0065734898671507835 \nEpoch: 300 | Loss: 0.006479030475020409 \nEpoch: 301 | Loss: 0.0063859522342681885 \nEpoch: 302 | Loss: 0.0062941741198301315 \nEpoch: 303 | Loss: 0.006203702185302973 \nEpoch: 304 | Loss: 0.00611457135528326 \nEpoch: 305 | Loss: 0.006026685703545809 \nEpoch: 306 | Loss: 0.005940036848187447 \nEpoch: 307 | Loss: 0.005854682996869087 \nEpoch: 308 | Loss: 0.005770542658865452 \nEpoch: 309 | Loss: 0.0056876083835959435 \nEpoch: 310 | Loss: 0.005605883430689573 \nEpoch: 311 | Loss: 0.005525293760001659 \nEpoch: 312 | Loss: 0.005445906426757574 \nEpoch: 313 | Loss: 0.005367639008909464 \nEpoch: 314 | Loss: 0.0052904654294252396 \nEpoch: 315 | Loss: 0.005214443430304527 \nEpoch: 316 | Loss: 0.0051395101472735405 \nEpoch: 317 | Loss: 0.005065672565251589 \nEpoch: 318 | Loss: 0.004992891568690538 \nEpoch: 319 | Loss: 0.004921101965010166 \nEpoch: 320 | Loss: 0.004850403405725956 \nEpoch: 321 | Loss: 0.004780682735145092 \nEpoch: 322 | Loss: 0.0047119613736867905 \nEpoch: 323 | Loss: 0.004644264467060566 \nEpoch: 324 | Loss: 0.00457746721804142 \nEpoch: 325 | Loss: 0.004511703737080097 \nEpoch: 326 | Loss: 0.004446889739483595 \nEpoch: 327 | Loss: 0.004382967948913574 \nEpoch: 328 | Loss: 0.004319974686950445 \nEpoch: 329 | Loss: 0.00425790436565876 \nEpoch: 330 | Loss: 0.00419672392308712 \nEpoch: 331 | Loss: 0.0041363900527358055 \nEpoch: 332 | Loss: 0.004076946526765823 \nEpoch: 333 | Loss: 0.0040183416567742825 \nEpoch: 334 | Loss: 0.00396060012280941 \nEpoch: 335 | Loss: 0.003903687233105302 \nEpoch: 336 | Loss: 0.0038475864566862583 \nEpoch: 337 | Loss: 0.0037922929041087627 \nEpoch: 338 | Loss: 0.0037377974949777126 \nEpoch: 339 | Loss: 0.003684067167341709 \nEpoch: 340 | Loss: 0.003631094004958868 \nEpoch: 341 | Loss: 0.003578962991014123 \nEpoch: 342 | Loss: 0.0035275062546133995 \nEpoch: 343 | Loss: 0.0034767957404255867 \nEpoch: 344 | Loss: 0.0034268167801201344 \nEpoch: 345 | Loss: 0.0033776015043258667 \nEpoch: 346 | Loss: 0.003329067723825574 \nEpoch: 347 | Loss: 0.0032812049612402916 \nEpoch: 348 | Loss: 0.0032340590842068195 \nEpoch: 349 | Loss: 0.0031875823624432087 \nEpoch: 350 | Loss: 0.0031417454592883587 \nEpoch: 351 | Loss: 0.003096612635999918 \nEpoch: 352 | Loss: 0.003052095416933298 \nEpoch: 353 | Loss: 0.003008222673088312 \nEpoch: 354 | Loss: 0.002965006045997143 \nEpoch: 355 | Loss: 0.0029224164318293333 \nEpoch: 356 | Loss: 0.002880403306335211 \nEpoch: 357 | Loss: 0.002838995074853301 \nEpoch: 358 | Loss: 0.0027982124593108892 \nEpoch: 359 | Loss: 0.0027579786255955696 \nEpoch: 360 | Loss: 0.0027183452621102333 \nEpoch: 361 | Loss: 0.0026792692951858044 \nEpoch: 362 | Loss: 0.002640772145241499 \nEpoch: 363 | Loss: 0.002602844499051571 \nEpoch: 364 | Loss: 0.0025654092896729708 \nEpoch: 365 | Loss: 0.002528572455048561 \nEpoch: 366 | Loss: 0.002492210827767849 \nEpoch: 367 | Loss: 0.002456400776281953 \nEpoch: 368 | Loss: 0.0024211020208895206 \nEpoch: 369 | Loss: 0.002386294072493911 \nEpoch: 370 | Loss: 0.002351994626224041 \nEpoch: 371 | Loss: 0.002318187616765499 \nEpoch: 372 | Loss: 0.0022848944645375013 \nEpoch: 373 | Loss: 0.0022520548664033413 \nEpoch: 374 | Loss: 0.00221969373524189 \nEpoch: 375 | Loss: 0.0021877954714000225 \nEpoch: 376 | Loss: 0.0021563307382166386 \nEpoch: 377 | Loss: 0.0021253509912639856 \nEpoch: 378 | Loss: 0.002094810828566551 \nEpoch: 379 | Loss: 0.00206471118144691 \nEpoch: 380 | Loss: 0.0020350259728729725 \nEpoch: 381 | Loss: 0.002005769405514002 \nEpoch: 382 | Loss: 0.001976977800950408 \nEpoch: 383 | Loss: 0.0019485459197312593 \nEpoch: 384 | Loss: 0.001920531503856182 \nEpoch: 385 | Loss: 0.001892950152978301 \nEpoch: 386 | Loss: 0.0018657288746908307 \nEpoch: 387 | Loss: 0.0018389292526990175 \nEpoch: 388 | Loss: 0.0018124966882169247 \nEpoch: 389 | Loss: 0.0017864546971395612 \nEpoch: 390 | Loss: 0.0017607570625841618 \nEpoch: 391 | Loss: 0.0017354735173285007 \nEpoch: 392 | Loss: 0.00171053153462708 \nEpoch: 393 | Loss: 0.0016859275056049228 \nEpoch: 394 | Loss: 0.0016616961220279336 \nEpoch: 395 | Loss: 0.001637842389754951 \nEpoch: 396 | Loss: 0.0016142944805324078 \nEpoch: 397 | Loss: 0.0015910700894892216 \nEpoch: 398 | Loss: 0.0015682211378589272 \nEpoch: 399 | Loss: 0.0015456974506378174 \nEpoch: 400 | Loss: 0.0015234684105962515 \nEpoch: 401 | Loss: 0.0015015625394880772 \nEpoch: 402 | Loss: 0.0014799898490309715 \nEpoch: 403 | Loss: 0.0014587196055799723 \nEpoch: 404 | Loss: 0.0014377711340785027 \nEpoch: 405 | Loss: 0.001417085761204362 \nEpoch: 406 | Loss: 0.0013967326376587152 \nEpoch: 407 | Loss: 0.0013766670599579811 \nEpoch: 408 | Loss: 0.0013568815775215626 \nEpoch: 409 | Loss: 0.001337373279966414 \nEpoch: 410 | Loss: 0.0013181539252400398 \nEpoch: 411 | Loss: 0.0012992164120078087 \nEpoch: 412 | Loss: 0.0012805531732738018 \nEpoch: 413 | Loss: 0.0012621323112398386 \nEpoch: 414 | Loss: 0.0012439965503290296 \nEpoch: 415 | Loss: 0.0012261042138561606 \nEpoch: 416 | Loss: 0.0012085151392966509 \nEpoch: 417 | Loss: 0.0011911174515262246 \nEpoch: 418 | Loss: 0.001174013246782124 \nEpoch: 419 | Loss: 0.0011571475770324469 \nEpoch: 420 | Loss: 0.0011405216064304113 \nEpoch: 421 | Loss: 0.0011241153115406632 \nEpoch: 422 | Loss: 0.0011079595424234867 \nEpoch: 423 | Loss: 0.001092051388695836 \nEpoch: 424 | Loss: 0.0010763402096927166 \nEpoch: 425 | Loss: 0.0010608718730509281 \nEpoch: 426 | Loss: 0.001045629964210093 \nEpoch: 427 | Loss: 0.001030606683343649 \nEpoch: 428 | Loss: 0.001015790388919413 \nEpoch: 429 | Loss: 0.001001193537376821 \nEpoch: 430 | Loss: 0.0009867954067885876 \nEpoch: 431 | Loss: 0.0009726249263621867 \nEpoch: 432 | Loss: 0.0009586343658156693 \nEpoch: 433 | Loss: 0.0009448720375075936 \nEpoch: 434 | Loss: 0.0009312943438999355 \nEpoch: 435 | Loss: 0.0009178995387628675 \nEpoch: 436 | Loss: 0.0009047188796103001 \nEpoch: 437 | Loss: 0.0008917099912650883 \nEpoch: 438 | Loss: 0.0008788969716988504 \nEpoch: 439 | Loss: 0.0008662554319016635 \nEpoch: 440 | Loss: 0.0008538091205991805 \nEpoch: 441 | Loss: 0.0008415337651968002 \nEpoch: 442 | Loss: 0.0008294545114040375 \nEpoch: 443 | Loss: 0.0008175374241545796 \nEpoch: 444 | Loss: 0.0008057741797529161 \nEpoch: 445 | Loss: 0.0007942010415717959 \nEpoch: 446 | Loss: 0.0007827767403796315 \nEpoch: 447 | Loss: 0.0007715384708717465 \nEpoch: 448 | Loss: 0.0007604520651511848 \nEpoch: 449 | Loss: 0.0007495048339478672 \nEpoch: 450 | Loss: 0.0007387507357634604 \nEpoch: 451 | Loss: 0.0007281260914169252 \nEpoch: 452 | Loss: 0.0007176734507083893 \nEpoch: 453 | Loss: 0.0007073520682752132 \nEpoch: 454 | Loss: 0.0006971837137825787 \nEpoch: 455 | Loss: 0.0006871712394058704 \nEpoch: 456 | Loss: 0.0006772842025384307 \nEpoch: 457 | Loss: 0.0006675469339825213 \nEpoch: 458 | Loss: 0.000657963624689728 \nEpoch: 459 | Loss: 0.0006485015037469566 \nEpoch: 460 | Loss: 0.0006391842616721988 \nEpoch: 461 | Loss: 0.0006299900123849511 \nEpoch: 462 | Loss: 0.000620952108874917 \nEpoch: 463 | Loss: 0.000612018397077918 \nEpoch: 464 | Loss: 0.0006032250821590424 \nEpoch: 465 | Loss: 0.000594547891523689 \nEpoch: 466 | Loss: 0.0005860207602381706 \nEpoch: 467 | Loss: 0.0005775804165750742 \nEpoch: 468 | Loss: 0.0005692901322618127 \nEpoch: 469 | Loss: 0.0005611092783510685 \nEpoch: 470 | Loss: 0.0005530368653126061 \nEpoch: 471 | Loss: 0.0005450976314023137 \nEpoch: 472 | Loss: 0.0005372615996748209 \nEpoch: 473 | Loss: 0.0005295465234667063 \nEpoch: 474 | Loss: 0.0005219337763264775 \nEpoch: 475 | Loss: 0.0005144275492057204 \nEpoch: 476 | Loss: 0.0005070333136245608 \nEpoch: 477 | Loss: 0.0004997432697564363 \nEpoch: 478 | Loss: 0.0004925718531012535 \nEpoch: 479 | Loss: 0.0004854881262872368 \nEpoch: 480 | Loss: 0.0004785053024534136 \nEpoch: 481 | Loss: 0.0004716387193184346 \nEpoch: 482 | Loss: 0.0004648506292141974 \nEpoch: 483 | Loss: 0.0004581702232826501 \nEpoch: 484 | Loss: 0.00045158882858231664 \nEpoch: 485 | Loss: 0.0004451028653420508 \nEpoch: 486 | Loss: 0.0004387100925669074 \nEpoch: 487 | Loss: 0.0004323986649978906 \nEpoch: 488 | Loss: 0.00042617975850589573 \nEpoch: 489 | Loss: 0.00042005477007478476 \nEpoch: 490 | Loss: 0.0004140214005019516 \nEpoch: 491 | Loss: 0.00040806696051731706 \nEpoch: 492 | Loss: 0.000402208068408072 \nEpoch: 493 | Loss: 0.0003964240022469312 \nEpoch: 494 | Loss: 0.000390726636396721 \nEpoch: 495 | Loss: 0.0003851150395348668 \nEpoch: 496 | Loss: 0.00037957343738526106 \nEpoch: 497 | Loss: 0.00037412485107779503 \nEpoch: 498 | Loss: 0.00036874247598461807 \nEpoch: 499 | Loss: 0.0003634445311035961 \n"
     ]
    }
   ],
   "source": [
    "# our model\n",
    "model = Model()\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    # 1) Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # 2) Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(f'Epoch: {epoch} | Loss: {loss.item()} ')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_XD8DN2n9ob",
    "outputId": "f3e361f3-85cf-4093-bc66-c42bd4a8e8b9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction (after training) 4 7.978084564208984\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "hour_var = tensor([[4.0]])\n",
    "y_pred = model(hour_var)\n",
    "print(\"Prediction (after training)\", 4, model(hour_var).data[0][0].item())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0x02 Logistic Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "jupytext": {
   "comment_magics": false
  },
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}