{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"name":"0x02 Logistic Regression.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"A--sgCKzn9oD","colab_type":"text"},"source":["# Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"KFBDBTV_n9oE","colab_type":"text"},"source":["## simple input"]},{"cell_type":"code","metadata":{"id":"v5Gd8ez6n9oF","colab_type":"code","colab":{}},"source":["from torch import tensor\n","from torch import nn\n","from torch import sigmoid\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"giA9i3Unn9oM","colab_type":"code","colab":{}},"source":["# Training data and ground truth\n","x_data = tensor([[1.0], [2.0], [3.0], [4.0]])\n","y_data = tensor([[0.], [0.], [1.], [1.]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEytgyTRn9oS","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","    def __init__(self):\n","        \"\"\"\n","        In the constructor we instantiate nn.Linear module\n","        \"\"\"\n","        super(Model, self).__init__()\n","        self.linear = nn.Linear(1, 1)  # One in and one out\n","\n","    def forward(self, x):\n","        \"\"\"\n","        In the forward function we accept a Variable of input data and we must return\n","        a Variable of output data.\n","        \"\"\"\n","        y_pred = sigmoid(self.linear(x))\n","        return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWMZ2Zl-n9oW","colab_type":"code","colab":{},"outputId":"3e22e72b-4a95-465b-e87d-48410d2cdbba"},"source":["# our model\n","model = Model()\n","\n","# Construct our loss function and an Optimizer. The call to model.parameters()\n","# in the SGD constructor will contain the learnable parameters of the two\n","# nn.Linear modules which are members of the model.\n","criterion = nn.BCELoss(reduction='mean')\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Training loop\n","for epoch in range(1000):\n","    # Forward pass: Compute predicted y by passing x to the model\n","    y_pred = model(x_data)\n","\n","    # Compute and print loss\n","    loss = criterion(y_pred, y_data)\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch + 1}/1000 | Loss: {loss.item():.4f}')\n","\n","    # Zero gradients, perform a backward pass, and update the weights.\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/1000 | Loss: 1.3503\n","Epoch 101/1000 | Loss: 0.7784\n","Epoch 201/1000 | Loss: 0.7337\n","Epoch 301/1000 | Loss: 0.7017\n","Epoch 401/1000 | Loss: 0.6720\n","Epoch 501/1000 | Loss: 0.6443\n","Epoch 601/1000 | Loss: 0.6184\n","Epoch 701/1000 | Loss: 0.5943\n","Epoch 801/1000 | Loss: 0.5718\n","Epoch 901/1000 | Loss: 0.5508\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a_XD8DN2n9ob","colab_type":"code","colab":{},"outputId":"f3e361f3-85cf-4093-bc66-c42bd4a8e8b9"},"source":["# After training\n","print(f'\\nLet\\'s predict the hours need to score above 50%\\n{\"=\" * 50}')\n","hour_var = model(tensor([[1.0]]))\n","print(\n","    f'Prediction after 1 hour of training: {hour_var.item():.4f} | Above 50%: {hour_var.item() > 0.5}')\n","hour_var = model(tensor([[7.0]]))\n","print(\n","    f'Prediction after 7 hours of training: {hour_var.item():.4f} | Above 50%: { hour_var.item() > 0.5}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Let's predict the hours need to score above 50%\n","==================================================\n","Prediction after 1 hour of training: 0.4673 | Above 50%: False\n","Prediction after 7 hours of training: 0.9340 | Above 50%: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q5xDtH1Xn9oh","colab_type":"text"},"source":["## multiple inputs\n","\n","https://pytorch.org/docs/stable/nn.html?highlight=bceloss#torch.nn.BCELoss\n","\n","https://en.wikipedia.org/wiki/Cross_entropy"]},{"cell_type":"code","metadata":{"id":"B4r9yxl8n9oi","colab_type":"code","colab":{}},"source":["from torch import nn, optim, from_numpy\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvzmIJMPn9om","colab_type":"code","colab":{},"outputId":"29124f9b-1575-43a4-fb9d-d700267bced0"},"source":["xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n","x_data = from_numpy(xy[:, 0:-1])\n","y_data = from_numpy(xy[:, [-1]])\n","print(f'X\\'s shape: {x_data.shape} | Y\\'s shape: {y_data.shape}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X's shape: torch.Size([759, 8]) | Y's shape: torch.Size([759, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"40V2q7jCn9oq","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","    def __init__(self):\n","        \"\"\"\n","        In the constructor we instantiate two nn.Linear module\n","        \"\"\"\n","        super(Model, self).__init__()\n","        self.l1 = nn.Linear(8, 6)\n","        self.l2 = nn.Linear(6, 4)\n","        self.l3 = nn.Linear(4, 1)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        \"\"\"\n","        In the forward function we accept a Variable of input data and we must return\n","        a Variable of output data. We can use Modules defined in the constructor as\n","        well as arbitrary operators on Variables.\n","        \"\"\"\n","        out1 = self.sigmoid(self.l1(x))\n","        out2 = self.sigmoid(self.l2(out1))\n","        y_pred = self.sigmoid(self.l3(out2))\n","        return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn3x_glLn9ou","colab_type":"code","colab":{}},"source":["# our model\n","model = Model()\n","\n","\n","# Construct our loss function and an Optimizer. The call to model.parameters()\n","# in the SGD constructor will contain the learnable parameters of the two\n","# nn.Linear modules which are members of the model.\n","criterion = nn.BCELoss(reduction='mean')  # binary cross entropy\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6bo5wF7n9oy","colab_type":"code","colab":{},"outputId":"ae9f4149-6e66-4d0b-b09e-1736cc76aa1c"},"source":["# Training loop\n","for epoch in range(100):\n","    # Forward pass: Compute predicted y by passing x to the model\n","    y_pred = model(x_data)\n","\n","    # Compute and print loss\n","    loss = criterion(y_pred, y_data)\n","    if epoch % 10 == 0:\n","        print(f'Epoch: {epoch + 1}/100 | Loss: {loss.item():.4f}')\n","\n","    # Zero gradients, perform a backward pass, and update the weights.\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1/100 | Loss: 0.6840\n","Epoch: 11/100 | Loss: 0.6576\n","Epoch: 21/100 | Loss: 0.6493\n","Epoch: 31/100 | Loss: 0.6466\n","Epoch: 41/100 | Loss: 0.6456\n","Epoch: 51/100 | Loss: 0.6453\n","Epoch: 61/100 | Loss: 0.6452\n","Epoch: 71/100 | Loss: 0.6452\n","Epoch: 81/100 | Loss: 0.6451\n","Epoch: 91/100 | Loss: 0.6451\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8jjyoOj3n9o2","colab_type":"code","colab":{},"outputId":"96d3f902-0772-4dbf-fc4a-a11071e8ca0d"},"source":["# Since I don't have additional data to text...\n","var = model(x_data)\n","print((y_data - var).mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0.0010, grad_fn=<MeanBackward0>)\n"],"name":"stdout"}]}]}